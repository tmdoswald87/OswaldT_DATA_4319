{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron in Julia 1.0.0\n",
    "\n",
    "### By Thomas Oswald\n",
    "\n",
    "#### Data 3419, Spring 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer Perceptron (MLP) is a class of feedforward artificial neural network.  In this notebook, I will demonstrate backpropgation for supervised learning on a training data set and show that data that isnt lineraly separable can still be distinguished from each other.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data set consists of $70000$ images of hand written digits, $60000$ of which are typically used as labeled training examples, where the other $10000$ are used for testing your learning model on. The following picture represent a sample of some of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the following packages if you havent already.\n",
    "\n",
    "* Pkg.add(\"MLDatasets\")\n",
    "* Pkg.add(\"MLDatasets\")\n",
    "* Pkg.add(\"TestImages\")\n",
    "* Pkg.add(\"ImageMagick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "...\n",
       "\n",
       "Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [7, 2, 1, 0, 4, 1, 4, 9, 5, 9  …  7, 8, 9, 0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg\n",
    "using Plots\n",
    "theme(:dark)\n",
    "using MLDatasets, Images, TestImages\n",
    "\n",
    "train_x, train_y = MNIST.traindata()\n",
    "test_x, test_y = MNIST.testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAG2SURBVGje7de9axVBGMXhR43cJils/EALIUERQSwEQSwSUolFUgdRO60FEf8AGz+wUQs7+1hEsNMqhSKEVFaxEURLERRRNFjMBi9ycTfe4H0Z3lPt7Mzsj7OHdz5IpVKpVCqVSqVGr23/MukA5nAFXzGPNx3nbv/fDusHbjrDHXiEhb53L3EqqsP6gZvK8CCe4kjTXmw+MIc7uB7RYf3AzhlO4yGmsIaLSv0dV3IdwwxeR3NYP7BThruxhBN4gvP40tc/g+dN33w0h/UDWzPsYVmpt2u4O2DMLqX+PuNQNIf1A8faBlxV6u+BwflR1te9up1N6/+l8TK8gBXcGtC3ExO43LQzw5EAWzOEZ3jf1+7hNM4od0RYx+2IDusHtu6Ha5hUamzjzHlSWTvhMY7iB45FdFg/sDXDc7ivrJkbE97hnlJ3P5W74TguRXRYP7DT3aL3x8B1fG+eD+MVbuJGRIf1Azvth9/+0rfH7xoN6bB+YKcMu2g1qsP6gUNneFbZH19EdVg/cOgMx/EBH6M6TGAC4wOHrsNZfIrssH7gUBnuw36Z4YiBW3IufRvZYf3AVCo1ev0CVsY3x/XyaGcAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 reinterpret(Gray{N0f8}, ::LinearAlgebra.Adjoint{Normed{UInt8,8},Array{Normed{UInt8,8},2}}):\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                                  \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of entries in dataset\n",
    "num_train = size(train_x)[3]\n",
    "\n",
    "# View the image\n",
    "rand_int = rand(1:num_train)\n",
    "colorview(Gray, train_x[:,:,rand_int]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000-element Array{Tuple{Array{Normed{UInt8,8},1},Array{Float64,1}},1}:\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ⋮                                                                                                                                                            \n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the vectors of data\n",
    "X_training = []\n",
    "Y_training = []\n",
    "\n",
    "# dimensions of a entry\n",
    "dim = length(train_x[:,:,rand_int])\n",
    "\n",
    "# 60,000 entries for this MNIST dataset\n",
    "for i = 1:num_train\n",
    "    if train_y[i] in [0,1,2,3,4,5,6,7,8,9]\n",
    "        push!(X_training, reshape(train_x[:,:,i], dim))\n",
    "        y = zeros(10)\n",
    "        if train_y[i] == 0                \n",
    "            y[1] = 1.0\n",
    "        elseif train_y[i] == 1             \n",
    "            y[2] = 1.0\n",
    "        elseif train_y[i] == 2             \n",
    "            y[3] = 1.0\n",
    "        elseif train_y[i] == 3            \n",
    "            y[4] = 1.0\n",
    "        elseif train_y[i] == 4             \n",
    "            y[5] = 1.0\n",
    "        elseif train_y[i] == 5             \n",
    "            y[6] = 1.0\n",
    "        elseif train_y[i] == 6            \n",
    "            y[7] = 1.0\n",
    "        elseif train_y[i] == 7             \n",
    "            y[8] = 1.0\n",
    "        elseif train_y[i] == 8            \n",
    "            y[9] = 1.0\n",
    "        else                               \n",
    "            y[10] = 1.0              \n",
    "        end\n",
    "        push!(Y_training,y)\n",
    "    end\n",
    "end\n",
    "    \n",
    "data_train = [x for x in zip(X_training, Y_training)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Array{Float64,1},1}:\n",
       " [0.0]                                                                                                                                                                                                      \n",
       " [-0.315443, -1.88971, -0.742304, 1.12742, 0.604818, -0.795429, -1.596, 0.713184, 0.417807, 1.60711  …  -0.464436, 0.674649, -0.735093, 1.34314, 0.560143, -1.16277, -1.13933, 0.562701, 1.20797, -0.208976]\n",
       " [3.14582, 0.624976, -1.04921, 1.90262, 0.079974, 0.257778, 1.33338, 0.0796784, 0.285397, 1.53517, -0.298704, 0.839363, -0.0483696, 0.33869, -1.25246, 0.795263]                                            \n",
       " [-0.130552, -0.046462, -1.20329, -0.417056, -0.190467, -0.307903, -0.92665, 0.705676, 0.883336, -0.382935]                                                                                                 \n",
       " [-0.418379, -0.214129, -0.184441, -0.0444582, 0.214724, -0.0627494, -1.50999, -0.335364, 0.688643, 0.533458]                                                                                               "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup initial weight values and bias values\n",
    "W2_test = randn(32,784)\n",
    "W3_test = randn(16,32)\n",
    "W4_test = randn(10,16)\n",
    "W5_test = randn(10,10)\n",
    "W_test = [[0.0], W2_test, W3_test, W4_test, W5_test]\n",
    "\n",
    "bias_test = [[0.0], randn(32),randn(16),randn(10),randn(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "back_prop (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sigmoid Function\n",
    "function σ(v)\n",
    "    return 1.0/(1.0 + exp(-v))\n",
    "end\n",
    "\n",
    "# chain rule on sigmoid\n",
    "function dσ(v)\n",
    "    return σ(v)*(1.0 - σ(v))\n",
    "end\n",
    "\n",
    "# calculate the pre and post activations for each layer for a given input x\n",
    "function forward_pass(W,b,x)\n",
    "    \n",
    "    z1 = [0.0]\n",
    "    a1 = x[1]\n",
    "    \n",
    "    z2 = W[2]*a1 + b[2]\n",
    "    a2 = σ.(z2) \n",
    "    z3 = W[3]*a2 + b[3]\n",
    "    a3 = σ.(z3)\n",
    "    z4 = W[4]*a3 + b[4]\n",
    "    a4 = σ.(z4)\n",
    "    z5 = W[5]*a4 + b[5]\n",
    "    a5 = σ.(z5)\n",
    "    \n",
    "    \n",
    "    return [(z1,a1),(z2,a2),(z3,a3),(z4,a4),(z5,a5)]\n",
    "end\n",
    "\n",
    "function output_error(W,b,x)\n",
    "    activations = forward_pass(W,b,x)\n",
    "    return (activations[5][2] - x[2]).*dσ.(activations[5][1])\n",
    "end\n",
    "\n",
    "function back_prop(W,b,x)\n",
    "    \n",
    "    δ5 = output_error(W,b,x)\n",
    "    activations = forward_pass(W,b,x)\n",
    "    δ4 = (W[5]'*δ5).*(dσ.(activations[4][1]))\n",
    "    δ3 = (W[4]'*δ4).*(dσ.(activations[3][1]))\n",
    "    δ2 = (W[3]'*δ3).*(dσ.(activations[2][1]))\n",
    "    \n",
    "    return [[0.0],δ2,δ3,δ4,δ5]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will perform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stochastic_Gradient_Descent (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Stochastic_Gradient_Descent(iterations, num, W_test, bias_test, data, rate)\n",
    "    for j = 1:iterations\n",
    "        for i = 1:num\n",
    "            activations = forward_pass(W_test, bias_test, data[i])\n",
    "            deltas = back_prop(W_test, bias_test, data[i])\n",
    "            \n",
    "             # update Bias # rate = learning rate\n",
    "            bias_test[5] -= (rate)*deltas[5]\n",
    "            bias_test[4] -= (rate)*deltas[4]\n",
    "            bias_test[3] -= (rate)*deltas[3]\n",
    "            bias_test[2] -= (rate)*deltas[2]\n",
    "            \n",
    "            # update Weights\n",
    "            W_test[5] -= (rate)*deltas[5]*activations[4][2]'\n",
    "            W_test[4] -= (rate)*deltas[4]*activations[3][2]'\n",
    "            W_test[3] -= (rate)*deltas[3]*activations[2][2]'\n",
    "            W_test[2] -= (rate)*deltas[2]*activations[1][2]'\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stochastic_Gradient_Descent(100,num_train, W_test,bias_test, data_train, 0.70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the MNIST training data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy_check (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Predict(num, data)\n",
    "    max_weight = findmax(forward_pass(W_test, bias_test, data[num])[5][2]) # find the max weight and the row it is on\n",
    "    max_data = findmax(data[num][2]) # Find what row the identifier is on.\n",
    "    \n",
    "    if max_weight[2] == max_data[2] # check to see if the row with the maximum weight is the same row for the number identifier\n",
    "        println(\"Success! The entry \",num,\", corresponds with the number \", max_data[2]-1)\n",
    "    else\n",
    "        println(\"Not a match! The entry \",num,\" does not correspond with the number \", max_data[2]-1)\n",
    "        println(\"The maximum weight is \",max_weight[1],\" and is on the \",max_weight[2],\" row.\")\n",
    "        println(\"For this number \",max_data[2]-1,\", it should be on the \",max_data[2],\" row of the last ativation layer.\")\n",
    "        println(\"This entry is being misclassified as a \",max_weight[2]-1,\".\")\n",
    "    end\n",
    "    println(\"\")\n",
    "    println(\"Below is the what the handwritten number.\")\n",
    "    return colorview(Gray, reshape(data[num][1], (28,28))')\n",
    "end\n",
    "\n",
    "# to test how accurate gradient descent is with the current iteration setup.\n",
    "function accuracy_check(num,W_test,bias_test,data)\n",
    "    count = 0\n",
    "    for i = 1:num\n",
    "        if findmax(forward_pass(W_test, bias_test, data[i])[5][2])[2]-1 == findmax(data[i][2])[2]-1\n",
    "            count += 1\n",
    "        end\n",
    "    end\n",
    "    accuracy = (count/num)*100\n",
    "    println(\"With the current iteration setup, we are \",accuracy,\"% accurate on the training set weights\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! The entry 30569, corresponds with the number 8\n",
      "\n",
      "Below is the what the handwritten number.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAJaSURBVGje7dm7a1RBGAXwX6Ji4yNEDRaBpIimDQgWoph/wCgoAUHFRtBCDYgxiNhY2vgABTuVNOIDrQSxENJY+QBLX5DCYNIFsZBoMbNkXTfZG4tkGObAsjtz986Zcw/fN9/MpaCgoKCgoKDtf246hDPYg7nYdwzjFe5tX26F+ROurvrHdbiKfuzEWsG/mofX4/d4HLQbk/i10grzJ6wUhweEONvXZLZP0IEBbMQajAh+n8ONlVaYP2GlOBzCfvMxdxdX4u8ZrBLibgc+Y0u8tj0FhfkTVs6lMI0LeIzZhms3cTgqmMNTjKWgMH/CSh62xZm1472//evFx7r2JyG/jqaiMH/CSh5+F2KrEw+FvPoBR3DKfI6dtrh/K6Iwf8LKe4vLQl3Tg6+4H/tq/n0R9hzvUlOYP+GS9oe3cKJhtj9wEQ8wlaLC/AmXVNPMNOmbEuqZZBXmT1jZwz4cbJhhO9bjuLBOzlYYJ/9HmmYuHRPWwm2xPYk7wl6+M/bdw1mtfcz/kabnYS8eCecwtfqlT6hrBnBUODuFZ0KsJqUwf8JFPRzBeXTFmb0Rzmhumz8H3YoJoV6Fa/GeZBTmT7jgerhZiLGu2J7AsH9rz2/CnuI5NsVPUgrzJ2wah31CXuyP7QnsbTHQIF5GBYN4lYrC/AmbxuFuoX6ZE/bswy0G6BZyam29/J2SwvwJW+4tOnBSCNhGb9qwAafr+t4K9U4yCvMnbOlhDy6Zfx/RONta32v8xAvFw2XGguvhLuFse6huZjW/RoUzm/rYbPY+KgmF+RMWFBQUFBQU8AcF+WFkRk5pKQAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 reinterpret(Gray{N0f8}, ::LinearAlgebra.Adjoint{Normed{UInt8,8},Array{Normed{UInt8,8},2}}):\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                                  \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run several times if you like\n",
    "rand_int = rand(1:num_train)\n",
    "Predict(rand_int, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the current iteration setup, we are 92.14333333333333% accurate on the training set weights\n"
     ]
    }
   ],
   "source": [
    "accuracy_check(num_train,W_test,bias_test, data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we test this on the MNIST test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000-element Array{Tuple{Array{Normed{UInt8,8},1},Array{Float64,1}},1}:\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
       " ⋮                                                                                                                                                            \n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "# dimensions of a entry\n",
    "dim = length(test_x[:,:,1])\n",
    "\n",
    "# Number of entries in dataset\n",
    "num_test = size(test_x)[3]\n",
    "\n",
    "for i = 1:num_test    # 10,000 entries for this MNIST dataset\n",
    "    if test_y[i] in [0,1,2,3,4,5,6,7,8,9]\n",
    "        push!(X_test, reshape(test_x[:,:,i], dim))\n",
    "        y = zeros(10)\n",
    "        if test_y[i] == 0                \n",
    "            y[1] = 1.0\n",
    "        elseif test_y[i] == 1             \n",
    "            y[2] = 1.0\n",
    "        elseif test_y[i] == 2             \n",
    "            y[3] = 1.0\n",
    "        elseif test_y[i] == 3            \n",
    "            y[4] = 1.0\n",
    "        elseif test_y[i] == 4             \n",
    "            y[5] = 1.0\n",
    "        elseif test_y[i] == 5             \n",
    "            y[6] = 1.0\n",
    "        elseif test_y[i] == 6            \n",
    "            y[7] = 1.0\n",
    "        elseif test_y[i] == 7             \n",
    "            y[8] = 1.0\n",
    "        elseif test_y[i] == 8            \n",
    "            y[9] = 1.0\n",
    "        else                               \n",
    "            y[10] = 1.0              \n",
    "        end\n",
    "        push!(Y_test,y)\n",
    "    end\n",
    "end\n",
    "    \n",
    "data_test = [x for x in zip(X_test, Y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will perform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stochastic_Gradient_Descent(100,num_test, W_test,bias_test, data_test, 0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! The entry 4726, corresponds with the number 2\n",
      "\n",
      "Below is the what the handwritten number.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAHMSURBVGje7dm9axRBHMbxjxI5awvBTlPYiwgiQdCAIiIKIhgQRSFoYyUK1iKKoo1YWvgSC18Ki0CaFIKWsRb/gVR6hSRyKpzF7HFLCJd1A3H8MU81OzuzD89+mZmdWYqKioqKioo2NWl0BQ+q8hvM4D16LQw3b3TC+IaNGD7FuRWd5nAbH3NPGN+wEcOzOIwLGKs69fEbjySW3VwTxjdsxHCgQxLHCeyq1X/Dbs04xn+leTOsaxbHatfXDdfMrBLGNxxr2/EUzktz7FTOCeMbtmb4C0/wU2H4jw1bMxxoPPeE8Q3XxbCDE1V5MdeE8Q3XxXASe/AF73JNGN+wNcMtuFmVH2Mp14TxDVszfIgDVflTzgnjG7ZieASXpM3lUX933hb/lea9x98unZvewtaqrivtM7q4L52Jf88pYXzDRgw7uIHL2GF4Xlp/yOB6HifxI5eE8Q3XZDiOuzi9otMrvMW26t5k7f4zXMwlYXzDkQw7eI4zhuNsAftWabsX16R/HIsS0885JIxvOPKbZloaY30s44605q2mBVzFTuzHcYXhBqnRd2kPL6X/hKP0VeJ4EC9ySRjfcM259ANe497/mjC+YVFRUVFRURF/AAvVQGK8QF3AAAAAAElFTkSuQmCC",
      "text/plain": [
       "28×28 reinterpret(Gray{N0f8}, ::LinearAlgebra.Adjoint{Normed{UInt8,8},Array{Normed{UInt8,8},2}}):\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                                  \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run several times if you like\n",
    "rand_int2 = rand(1:num_test)\n",
    "Predict(rand_int2, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the current iteration setup, we are 93.85% accurate on the training set weights\n"
     ]
    }
   ],
   "source": [
    "accuracy_check(num_test,W_test,bias_test,data_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
